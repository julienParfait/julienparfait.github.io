---
title: Pipepline
publishDate: 2023-03-02 00:00:00
img: /assets/pipeline.png
img_alt: Dashboard
description: |
  In this article, I present the steps involved in building a pipeline and provide a site to help you understand the ETL process.
tags:
  - Pipeline 
  - Flux ETL
  - Pre processing
---

#### Overview

##### Pipeline for data wrangling

<p style="text-align: justify;">
A machine learning pipeline is a structuring tool used to automate and simplify the data processing and modelling workflow. It consists of an ordered sequence of steps, where each step corresponds to a specific transformation (pre-processing, feature selection, etc.) or learning model. The main objective of a pipeline is to guarantee consistent processing of the data, from preparation to training and prediction, while minimising the risk of manual errors. By encapsulating all the stages in a single entity, a pipeline promotes replicability, improves code readability and facilitates cross-validation of complete processes. It is therefore crucial in machine learning to develop robust and maintainable models, especially in environments where data preparation and model training require a high degree of consistency and rigour.
</p>

<br>

Link : <a href="https://julienparfait.github.io/pipelines-sklearn/pipe.html">Pipeline for data preprocessing</a> 
<br>


Link to the article on the ETL process : <a href="https://neptune.ai/blog/building-end-to-end-ml-pipeline">Neptune.</a>